# Cross-Repository Logging Architecture

**Date**: 2025-11-11  
**Updated**: 2025-11-11 (Simplified to Universal API + Sample Files)  
**Status**: Implementation in Progress  
**Purpose**: Enable DevSmith Logs/Analytics/Health to monitor ANY codebase

---

## üéØ Problem Statement

**Current State:**
- Health App only monitors DevSmith platform itself
- Logs service designed for internal use only
- Review App already works on any GitHub repository
- **Gap:** No way to collect logs/metrics from external projects

**Required Capabilities:**
1. Monitor logs from user's other projects (Node.js, Python, Go, Java, etc.)
2. Analyze performance metrics from any codebase
3. Track errors/warnings across multiple repositories
4. Provide health dashboards for external applications
5. Enable AI-powered log analysis for any project

**Use Cases:**
- Developer wants to monitor their production Node.js app
- Team wants centralized logging for microservices (different languages)
- DevOps engineer needs unified dashboard across 10+ repositories
- Startup wants error tracking without paying for Datadog/Sentry

---

## üèóÔ∏è Architecture: Universal REST API + Sample Integration Files

### Core Principle: Simple is Better

**Why NOT language-specific SDKs:**
- ‚ùå Maintenance burden (multiple codebases to update)
- ‚ùå Version hell (users stuck on old SDK versions)
- ‚ùå Limited language support (can't support every framework)
- ‚ùå Publishing complexity (npm, PyPI, Go modules, etc.)

**Why Universal API + Samples:**
- ‚úÖ Single source of truth (one API, many integrations)
- ‚úÖ Language-agnostic (works with ANY HTTP client)
- ‚úÖ Copy-paste ready (users customize for their needs)
- ‚úÖ Community contributions (easy to add new examples)
- ‚úÖ Zero maintenance (update API, samples follow)

### Architecture Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              User's External Applications                   ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  Node.js App ‚îÇ  ‚îÇ  Python API  ‚îÇ  ‚îÇ   Go Service ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  Copy-paste  ‚îÇ  ‚îÇ  Copy-paste  ‚îÇ  ‚îÇ  Copy-paste  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  logger.js   ‚îÇ  ‚îÇ  logger.py   ‚îÇ  ‚îÇ  logger.go   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  (50 lines)  ‚îÇ  ‚îÇ  (50 lines)  ‚îÇ  ‚îÇ  (50 lines)  ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ         ‚îÇ                  ‚îÇ                  ‚îÇ              ‚îÇ
‚îÇ         ‚îÇ   Batch logs     ‚îÇ   Batch logs     ‚îÇ Batch logs  ‚îÇ
‚îÇ         ‚îÇ   (100 logs or   ‚îÇ   (100 logs or   ‚îÇ (100 logs   ‚îÇ
‚îÇ         ‚îÇ    5 seconds)    ‚îÇ    5 seconds)    ‚îÇ  or 5s)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                  ‚îÇ                  ‚îÇ
          ‚îÇ  POST /api/logs/batch                ‚îÇ
          ‚îÇ  Authorization: Bearer dsk_...       ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ   DevSmith Batch Ingestion Endpoint  ‚îÇ
          ‚îÇ   POST /api/logs/batch               ‚îÇ
          ‚îÇ   - Validates API key                ‚îÇ
          ‚îÇ   - Batch INSERT (1 query)           ‚îÇ
          ‚îÇ   - 100x faster than individual logs ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ       DevSmith Platform Backend      ‚îÇ
          ‚îÇ                                      ‚îÇ
          ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
          ‚îÇ  ‚îÇ  Logs  ‚îÇ  ‚îÇAnalytics ‚îÇ          ‚îÇ
          ‚îÇ  ‚îÇService ‚îÇ  ‚îÇ Service  ‚îÇ          ‚îÇ
          ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
          ‚îÇ                                      ‚îÇ
          ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
          ‚îÇ  ‚îÇ    PostgreSQL          ‚îÇ         ‚îÇ
          ‚îÇ  ‚îÇ  logs.entries          ‚îÇ         ‚îÇ
          ‚îÇ  ‚îÇ  logs.projects         ‚îÇ  NEW!  ‚îÇ
          ‚îÇ  ‚îÇ  Batch INSERT support  ‚îÇ  NEW!  ‚îÇ
          ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ         Health Dashboard             ‚îÇ
          ‚îÇ  View logs from ANY project          ‚îÇ
          ‚îÇ  Filter by: project, service, level  ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Flow:**
1. User copies sample file (logger.js/logger.py/logger.go) into their app
2. User customizes with their API key (generated in DevSmith portal)
3. Sample logger buffers logs (100 logs or 5-second interval)
4. Batch sent to `/api/logs/batch` endpoint
5. Single database INSERT for entire batch
6. Health dashboard shows logs from all registered projects

**Performance:**
- Individual requests: 100 logs = 100 HTTP calls = 5-10 seconds
- Batch requests: 100 logs = 1 HTTP call + 1 DB query = ~50ms
- **100x faster with batching!**

---

### Alternative: Log File Ingestion (Future Phase)

**Concept:** DevSmith reads log files from mounted volumes or cloud storage.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      User's Application Server          ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  App writes to:                         ‚îÇ
‚îÇ  /var/log/myapp/*.log                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚îÇ Docker volume mount or
                  ‚îÇ S3 bucket sync
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     DevSmith Log Ingestion Service      ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Watches: /mnt/external-logs/*.log      ‚îÇ
‚îÇ  Parses: JSON, plaintext, syslog        ‚îÇ
‚îÇ  Enriches: timestamp, project_id        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚ñº
         DevSmith Logs Database
```

**Pros/Cons:**

| Aspect | Universal API (Primary) | File Ingestion (Alternative) |
|--------|------------------------|---------------------------|
| **Installation** | Copy-paste sample file | Mount volumes or configure S3 |
| **Language Support** | ANY language with HTTP | Works with any log format |
| **Real-time** | ‚úÖ Immediate | ‚ö†Ô∏è Delayed (file watching) |
| **Network** | Outbound HTTPS | File system or S3 API |
| **Metadata** | ‚úÖ Rich (service, version, etc.) | ‚ö†Ô∏è Limited (parsed from logs) |
| **Setup Complexity** | ‚úÖ Minimal (copy-paste) | ‚ö†Ô∏è Infrastructure changes |
| **Performance** | ‚úÖ 100x faster with batching | ‚ö†Ô∏è Depends on file size |
| **Best For** | New & existing apps | Legacy systems, existing logs |

**RECOMMENDATION: Start with Universal API**
- Simpler installation (copy-paste sample file)
- Better performance (batching optimized)
- Richer metadata (service name, custom fields)
- Add File Ingestion later for legacy systems that can't change code

---

## üîß Implementation Plan

### Phase 1: Database Schema (Week 1)

**Add project tracking:**

```sql
-- New table: projects (user-registered applications)
CREATE TABLE logs.projects (
    id SERIAL PRIMARY KEY,
    user_id INT NOT NULL,  -- Owner of this project
    name VARCHAR(255) NOT NULL,
    slug VARCHAR(100) NOT NULL UNIQUE,  -- URL-safe identifier
    description TEXT,
    repository_url VARCHAR(500),  -- Optional GitHub URL
    api_key_hash VARCHAR(255) NOT NULL,  -- Hashed API key for auth
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    is_active BOOLEAN DEFAULT true,
    
    UNIQUE(user_id, slug)
);

-- Index for fast lookup by API key
CREATE INDEX idx_projects_api_key ON logs.projects(api_key_hash);

-- Add project_id to log_entries
ALTER TABLE logs.entries ADD COLUMN project_id INT;
ALTER TABLE logs.entries ADD COLUMN service_name VARCHAR(100);

-- Foreign key (optional - allows logs to exist without project)
ALTER TABLE logs.entries ADD CONSTRAINT fk_project
    FOREIGN KEY (project_id) REFERENCES logs.projects(id)
    ON DELETE SET NULL;

-- Index for filtering by project
CREATE INDEX idx_entries_project ON logs.entries(project_id, created_at DESC);
CREATE INDEX idx_entries_service ON logs.entries(project_id, service_name, created_at DESC);
```

**Migration file:** `internal/logs/db/migrations/20251111_001_add_projects.sql`

---

### Phase 2: API Key Management (Week 1)

**New endpoints:**

```go
// POST /api/logs/projects
// Create new project and generate API key
type CreateProjectRequest struct {
    Name          string `json:"name" binding:"required"`
    Slug          string `json:"slug" binding:"required"`
    Description   string `json:"description"`
    RepositoryURL string `json:"repository_url"`
}

type CreateProjectResponse struct {
    ProjectID int    `json:"project_id"`
    Name      string `json:"name"`
    Slug      string `json:"slug"`
    APIKey    string `json:"api_key"`  // ONLY shown once!
    Message   string `json:"message"`
}

// GET /api/logs/projects
// List user's projects
type ListProjectsResponse struct {
    Projects []Project `json:"projects"`
}

type Project struct {
    ID            int       `json:"id"`
    Name          string    `json:"name"`
    Slug          string    `json:"slug"`
    Description   string    `json:"description"`
    RepositoryURL string    `json:"repository_url"`
    CreatedAt     time.Time `json:"created_at"`
    LogCount      int       `json:"log_count"`  // Total logs from this project
    IsActive      bool      `json:"is_active"`
}

// PUT /api/logs/projects/:id/regenerate-key
// Regenerate API key for project
type RegenerateKeyResponse struct {
    APIKey  string `json:"api_key"`  // New key
    Message string `json:"message"`
}

// DELETE /api/logs/projects/:id
// Deactivate project (soft delete)
```

**API Key Generation:**

```go
// internal/logs/services/project_service.go
func GenerateAPIKey() (string, string, error) {
    // Generate random key: "dsk_" + 32 random bytes (base64)
    randomBytes := make([]byte, 32)
    if _, err := rand.Read(randomBytes); err != nil {
        return "", "", err
    }
    
    apiKey := "dsk_" + base64.URLEncoding.EncodeToString(randomBytes)
    
    // Hash for storage (bcrypt)
    hash, err := bcrypt.GenerateFromPassword([]byte(apiKey), bcrypt.DefaultCost)
    if err != nil {
        return "", "", err
    }
    
    return apiKey, string(hash), nil
}

// Validate API key from request
func ValidateAPIKey(providedKey string, storedHash string) bool {
    err := bcrypt.CompareHashAndPassword([]byte(storedHash), []byte(providedKey))
    return err == nil
}
```

---

### Phase 3: Batch Ingestion Endpoint (Week 1)

**New endpoint:**

```go
// POST /api/logs/batch
// Batch log ingestion (100x faster than individual requests)
type BatchLogRequest struct {
    ProjectSlug string     `json:"project_slug" binding:"required"`
    ServiceName string     `json:"service_name" binding:"required"`
    Logs        []LogEntry `json:"logs" binding:"required,min=1"`
}

type LogEntry struct {
    Timestamp string                 `json:"timestamp"`
    Level     string                 `json:"level" binding:"required,oneof=DEBUG INFO WARN ERROR"`
    Message   string                 `json:"message" binding:"required"`
    Context   map[string]interface{} `json:"context"`
}

type BatchLogResponse struct {
    Count   int    `json:"count"`
    Message string `json:"message"`
}
```

**Handler implementation:**

```go
// internal/logs/handlers/batch_handler.go
func (h *BatchHandler) IngestBatch(c *gin.Context) {
    // 1. Validate API key from Authorization header
    apiKey := c.GetHeader("Authorization")
    if !strings.HasPrefix(apiKey, "Bearer dsk_") {
        c.JSON(401, gin.H{"error": "Invalid API key format"})
        return
    }
    
    apiKey = strings.TrimPrefix(apiKey, "Bearer ")
    
    // 2. Look up project by API key
    project, err := h.projectService.GetProjectByAPIKey(c.Request.Context(), apiKey)
    if err != nil {
        c.JSON(401, gin.H{"error": "Invalid or expired API key"})
        return
    }
    
    // 3. Parse batch request
    var req BatchLogRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(400, gin.H{"error": err.Error()})
        return
    }
    
    // 4. Convert to log entries with project_id
    entries := make([]*logs_models.LogEntry, len(req.Logs))
    for i, log := range req.Logs {
        entries[i] = &logs_models.LogEntry{
            UserID:      project.UserID,
            ProjectID:   project.ID,
            ServiceName: req.ServiceName,
            Level:       strings.ToUpper(log.Level),
            Message:     log.Message,
            Metadata:    log.Context,
        }
    }
    
    // 5. Batch insert (single query!)
    if err := h.logRepo.CreateBatch(c.Request.Context(), entries); err != nil {
        c.JSON(500, gin.H{"error": "Failed to store logs"})
        return
    }
    
    c.JSON(201, BatchLogResponse{
        Count:   len(entries),
        Message: fmt.Sprintf("Successfully ingested %d logs", len(entries)),
    })
}
```

**Performance:**
- **Single INSERT query** for 100 logs: ~10-50ms
- **100x faster** than 100 individual requests (5 seconds ‚Üí 50ms)
- **Database load**: 1 transaction instead of 100
- **Throughput**: 14,000-33,000 logs/second (with connection pool)

---

### Phase 4: Copy-Paste Sample Files (Week 2)

**No SDKs to maintain! Users copy-paste into their projects.**

**JavaScript Sample (50 lines):**

```javascript
// File: docs/integrations/javascript/logger.js
// Copy this file into your project!

class DevSmithLogger {
  constructor(apiKey, projectSlug, serviceName) {
    this.apiKey = apiKey;
    this.apiUrl = process.env.DEVSMITH_URL || 'http://localhost:3000/api/logs';
    this.projectSlug = projectSlug;
    this.serviceName = serviceName;
    this.buffer = [];
    this.batchSize = 100;
    this.flushInterval = 5000; // 5 seconds
    
    // Auto-flush timer
    setInterval(() => this.flush(), this.flushInterval);
    
    // Flush on process exit
    process.on('beforeExit', () => this.flush());
  }

  log(level, message, context = {}) {
    this.buffer.push({
      timestamp: new Date().toISOString(),
      level: level.toUpperCase(),
      message,
      context
    });
    
    if (this.buffer.length >= this.batchSize) {
      this.flush();
    }
  }

  async flush() {
    if (this.buffer.length === 0) return;
    
    const logs = this.buffer.splice(0, this.buffer.length);
    
    try {
      await fetch(`${this.apiUrl}/batch`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          project_slug: this.projectSlug,
          service_name: this.serviceName,
          logs
        })
      });
    } catch (error) {
      console.error('DevSmith: Failed to send logs:', error);
      // Optionally: save to disk for retry
    }
  }

  debug(msg, ctx) { this.log('DEBUG', msg, ctx); }
  info(msg, ctx) { this.log('INFO', msg, ctx); }
  warn(msg, ctx) { this.log('WARN', msg, ctx); }
  error(msg, ctx) { this.log('ERROR', msg, ctx); }
}

module.exports = DevSmithLogger;
```

**Usage (4 lines):**

```javascript
const DevSmithLogger = require('./logger');  // Copy-pasted file!

const logger = new DevSmithLogger('dsk_abc123', 'my-app', 'api-server');
logger.info('User logged in', { userId: 123 });
logger.error('Database error', { code: 'ECONNREFUSED' });
```

**Python Sample (50 lines):**

```python
# File: docs/integrations/python/logger.py
# Copy this file into your project!

import requests
import time
import atexit
import os
from datetime import datetime
from threading import Thread, Event

class DevSmithLogger:
    def __init__(self, api_key, project_slug, service_name):
        self.api_key = api_key
        self.api_url = os.getenv('DEVSMITH_URL', 'http://localhost:3000/api/logs')
        self.project_slug = project_slug
        self.service_name = service_name
        self.buffer = []
        self.batch_size = 100
        self.flush_interval = 5.0
        
        # Auto-flush thread
        self.stop_event = Event()
        self.flush_thread = Thread(target=self._auto_flush, daemon=True)
        self.flush_thread.start()
        
        # Flush on exit
        atexit.register(self.flush)
    
    def log(self, level, message, **context):
        self.buffer.append({
            'timestamp': datetime.utcnow().isoformat() + 'Z',
            'level': level.upper(),
            'message': message,
            'context': context
        })
        
        if len(self.buffer) >= self.batch_size:
            self.flush()
    
    def flush(self):
        if not self.buffer:
            return
        
        logs = self.buffer[:]
        self.buffer = []
        
        try:
            requests.post(
                f'{self.api_url}/batch',
                json={
                    'project_slug': self.project_slug,
                    'service_name': self.service_name,
                    'logs': logs
                },
                headers={'Authorization': f'Bearer {self.api_key}'},
                timeout=5
            )
        except Exception as e:
            print(f'DevSmith: Failed to send logs: {e}')
    
    def _auto_flush(self):
        while not self.stop_event.wait(self.flush_interval):
            self.flush()
    
    def debug(self, msg, **ctx): self.log('DEBUG', msg, **ctx)
    def info(self, msg, **ctx): self.log('INFO', msg, **ctx)
    def warn(self, msg, **ctx): self.log('WARN', msg, **ctx)
    def error(self, msg, **ctx): self.log('ERROR', msg, **ctx)
```

---

## üîê Security Considerations

### API Key Security

1. **Generation:**
   - Use cryptographically secure random bytes
   - Prefix: `dsk_` (DevSmith Key)
   - Length: 32 bytes (base64 encoded = 43 chars)
   - Example: `dsk_abc123xyz789...`

2. **Storage:**
   - NEVER store plain API keys in database
   - Use bcrypt to hash keys (same as passwords)
   - Only show plain key ONCE after generation
   - User must store securely (password manager, env vars)

3. **Transmission:**
   - HTTPS required in production
   - API key in `X-API-Key` header (not in URL)
   - Rate limiting per API key (1000 requests/minute)

4. **Rotation:**
   - Allow regenerating keys
   - Invalidate old key immediately
   - Log key rotation events

### Rate Limiting

```go
// Limit: 1000 requests per minute per API key
func RateLimitMiddleware(cache *redis.Client) gin.HandlerFunc {
    return func(c *gin.Context) {
        apiKey := c.GetHeader("X-API-Key")
        
        key := fmt.Sprintf("ratelimit:%s", apiKey)
        count, err := cache.Incr(c.Request.Context(), key).Result()
        
        if err == nil && count == 1 {
            cache.Expire(c.Request.Context(), key, 1*time.Minute)
        }
        
        if count > 1000 {
            c.JSON(http.StatusTooManyRequests, gin.H{
                "error": "Rate limit exceeded",
                "limit": 1000,
                "window": "1 minute"
            })
            c.Abort()
            return
        }
        
        c.Next()
    }
}
```

---

## üìä Deployment Options

### Option 1: Self-Hosted (DevSmith Platform on User's Server)

**User runs DevSmith on their own infrastructure:**

```bash
# User's server
git clone https://github.com/mikejsmith1985/devsmith-modular-platform.git
cd devsmith-modular-platform
docker-compose up -d

# Access at: http://their-server.com:3000
```

**Pros:**
- Full data control (logs never leave user's infrastructure)
- No external dependencies
- Free (no SaaS costs)

**Cons:**
- User must maintain infrastructure
- User responsible for backups/security

**SELECTED**: Self-hosted deployment for Week 1-4 MVP.

---

### Option 2: Hosted SaaS (DevSmith.io) - Future Phase

**You host DevSmith as a service (Phase 2+):**

```
Users sign up at: https://devsmith.io
Get API key from dashboard
Copy sample file to their app
Logs sent to: https://api.devsmith.io/logs/batch
```

**Pros:**
- No infrastructure management for users
- Easy onboarding
- Revenue opportunity (paid plans)

**Cons:**
- You manage multi-tenancy
- You handle scaling
- Security compliance (SOC 2, GDPR)

---

### Option 3: Hybrid (Cloud + On-Prem Agents) - Future Phase

**DevSmith hosted, but agents can run on-premise (Phase 3+):**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User's Private Network     ‚îÇ
‚îÇ                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  DevSmith Agent      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  (On-prem collector) ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Collects logs from: ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Internal services ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Databases         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Kubernetes        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ             ‚îÇ                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ HTTPS (outbound only)
              ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  DevSmith Cloud SaaS ‚îÇ
    ‚îÇ  https://devsmith.io ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Best of both worlds:**
- Users keep sensitive data on-prem
- You provide aggregation/analysis UI
- Agent opens outbound connection only (firewall-friendly)

---

## ÔøΩ Documentation Site

Create docs at `https://docs.devsmith.io` with:
- Quick start guides per language (JavaScript, Python, Go)
- Sample file customization guides
- API reference for batch endpoint
- Framework integration examples (Express, Flask, Gin)
- Troubleshooting guides
- Example integrations (Express, Flask, Gin)
- Troubleshooting

---

## üéØ MVP Implementation Timeline

### Week 1: Foundation ‚úÖ (75% Complete)
- ‚úÖ Database schema (projects table) - **DONE**
- ‚úÖ API key generation service - **DONE**
- ‚úÖ Project management models - **DONE**
- üîÑ Batch ingestion endpoint - **IN PROGRESS**
- ‚è≥ Project repository (database queries)
- ‚è≥ Project handler (REST endpoints)
- ‚è≥ Execute migration SQL
- ‚è≥ End-to-end testing

**Performance Target:** 14,000-33,000 logs/second with batching

### Week 2: Sample Integration Files (Changed from SDK Development)
- ‚è≥ Create `docs/integrations/javascript/logger.js` (50 lines)
- ‚è≥ Create `docs/integrations/python/logger.py` (50 lines)
- ‚è≥ Create `docs/integrations/go/logger.go` (60 lines)
- ‚è≥ Create Express.js middleware example
- ‚è≥ Create Flask decorator example
- ‚è≥ Create Gin middleware example
- ‚è≥ Write integration guide with copy-paste instructions
- ‚è≥ Performance testing (verify 100x speedup with batching)

**Why NOT SDKs:**
- ‚ùå No npm/PyPI/Go module maintenance
- ‚ùå No version compatibility issues
- ‚úÖ Users customize samples for their needs
- ‚úÖ Works with ANY language (even shell scripts!)

### Week 3: UI Updates
- ‚è≥ Project management page (CRUD operations)
- ‚è≥ API key display (show once on creation)
- ‚è≥ API key regeneration with confirmation
- ‚è≥ Health dashboard project filter dropdown
- ‚è≥ Service filter within selected project
- ‚è≥ Sample file documentation page

### Week 4: Testing & Documentation
- ‚è≥ Test sample files with real applications
- ‚è≥ Write integration guide (copy-paste workflow)
- ‚è≥ Load testing (target: 1M logs/hour = 14K+ logs/sec)
- ‚è≥ Security testing (API key validation, rate limiting)
- ‚è≥ Deploy to staging environment
- ‚è≥ Create troubleshooting guide

---

## üöÄ Future Enhancements

### Phase 2: Advanced Features
- **Rate Limiting Tiers:** Free (1K logs/day), Pro (100K logs/day), Enterprise (unlimited)
- **Log Sampling:** Sample 10% of logs in high-volume apps to reduce storage costs
- **Anomaly Detection:** ML-based anomaly detection on patterns
- **Webhook Notifications:** Real-time alerts via webhook on error spikes
- **Email/Slack Alerts:** Integrations for team notifications
- **Log Retention:** Configurable retention policies (7 days, 30 days, 90 days)
- **Export:** Export logs to S3/GCS/Azure Blob for long-term storage
- **Community Sample Gallery:** Users contribute samples for Ruby, PHP, Rust, C#, Java, etc.

### Phase 3: Enterprise Features
- **SSO Integration:** SAML/OAuth for enterprise auth
- **Role-Based Access:** Team members with different permissions (admin, developer, viewer)
- **Audit Logs:** Track who accessed what logs
- **Compliance:** SOC 2, HIPAA, GDPR compliance
- **Multi-Region Deployment:** Logs stored in user's region for compliance
- **On-Prem Deployment:** Docker images for private cloud
- **White-Label:** Custom branding for agencies managing multiple client projects

---

## üí° Example Use Cases

### Case 1: Monitoring Production Node.js App

```javascript
// File: logger.js (copy-paste from docs/integrations/javascript/logger.js)
const https = require('https');

class DevSmithLogger {
  constructor(config) {
    this.apiKey = config.apiKey;
    this.apiUrl = config.apiUrl;
    this.projectId = config.projectId;
    this.serviceName = config.serviceName;
    this.buffer = [];
    this.batchSize = 100;
    this.flushInterval = 5000;
    
    // Auto-flush every 5 seconds
    setInterval(() => this.flush(), this.flushInterval);
  }
  
  log(level, message, context = {}) {
    this.buffer.push({
      timestamp: new Date().toISOString(),
      level: level.toUpperCase(),
      message,
      context
    });
    
    if (this.buffer.length >= this.batchSize) {
      this.flush();
    }
  }
  
  flush() {
    if (this.buffer.length === 0) return;
    
    const logs = this.buffer.splice(0, this.buffer.length);
    const payload = JSON.stringify({
      project_id: this.projectId,
      service_name: this.serviceName,
      logs
    });
    
    const options = {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.apiKey}`,
        'Content-Type': 'application/json',
        'Content-Length': payload.length
      }
    };
    
    const req = https.request(`${this.apiUrl}/batch`, options);
    req.write(payload);
    req.end();
  }
  
  info(msg, ctx) { this.log('INFO', msg, ctx); }
  error(msg, ctx) { this.log('ERROR', msg, ctx); }
  warn(msg, ctx) { this.log('WARN', msg, ctx); }
}

module.exports = DevSmithLogger;

// User's Express.js app
const express = require('express');
const DevSmithLogger = require('./logger'); // Copy-pasted file

const logger = new DevSmithLogger({
  apiKey: process.env.DEVSMITH_API_KEY,
  apiUrl: 'https://devsmith.example.com/api/logs',
  projectId: 'my-ecommerce-api',
  serviceName: 'web-server'
});

const app = express();

// Log all requests
app.use((req, res, next) => {
  logger.info('HTTP request', {
    method: req.method,
    path: req.path,
    ip: req.ip
  });
  next();
});

// Log errors
app.use((err, req, res, next) => {
  logger.error('Unhandled error', {
    error: err.message,
    stack: err.stack,
    path: req.path
  });
  res.status(500).send('Internal Server Error');
});

app.listen(3000);
```

**User copies logger.js from docs, customizes config, and starts logging. Views logs in DevSmith Health dashboard filtered by "my-ecommerce-api" project.**

---

### Case 2: Microservices Logging with Go

```go
// File: logger.go (copy-paste from docs/integrations/go/logger.go)
package logger

import (
    "bytes"
    "encoding/json"
    "net/http"
    "sync"
    "time"
)

type DevSmithLogger struct {
    apiKey      string
    apiURL      string
    projectID   string
    serviceName string
    buffer      []LogEntry
    mutex       sync.Mutex
    batchSize   int
    httpClient  *http.Client
}

type LogEntry struct {
    Timestamp string                 `json:"timestamp"`
    Level     string                 `json:"level"`
    Message   string                 `json:"message"`
    Context   map[string]interface{} `json:"context"`
}

func NewLogger(apiKey, apiURL, projectID, serviceName string) *DevSmithLogger {
    l := &DevSmithLogger{
        apiKey:      apiKey,
        apiURL:      apiURL,
        projectID:   projectID,
        serviceName: serviceName,
        buffer:      make([]LogEntry, 0, 100),
        batchSize:   100,
        httpClient:  &http.Client{Timeout: 5 * time.Second},
    }
    
    // Auto-flush every 5 seconds
    go func() {
        ticker := time.NewTicker(5 * time.Second)
        for range ticker.C {
            l.Flush()
        }
    }()
    
    return l
}

func (l *DevSmithLogger) Log(level, message string, context map[string]interface{}) {
    l.mutex.Lock()
    defer l.mutex.Unlock()
    
    l.buffer = append(l.buffer, LogEntry{
        Timestamp: time.Now().UTC().Format(time.RFC3339),
        Level:     level,
        Message:   message,
        Context:   context,
    })
    
    if len(l.buffer) >= l.batchSize {
        l.flush()
    }
}

func (l *DevSmithLogger) Flush() {
    l.mutex.Lock()
    defer l.mutex.Unlock()
    l.flush()
}

func (l *DevSmithLogger) flush() {
    if len(l.buffer) == 0 {
        return
    }
    
    payload := map[string]interface{}{
        "project_id":   l.projectID,
        "service_name": l.serviceName,
        "logs":         l.buffer,
    }
    
    jsonData, _ := json.Marshal(payload)
    req, _ := http.NewRequest("POST", l.apiURL+"/batch", bytes.NewBuffer(jsonData))
    req.Header.Set("Authorization", "Bearer "+l.apiKey)
    req.Header.Set("Content-Type", "application/json")
    
    l.httpClient.Do(req)
    l.buffer = l.buffer[:0]
}

// docker-compose.yml for microservices
services:
  api-gateway:
    environment:
      - DEVSMITH_API_KEY=${DEVSMITH_API_KEY}
      - DEVSMITH_PROJECT=my-microservices
      - DEVSMITH_SERVICE=api-gateway
  
  user-service:
    environment:
      - DEVSMITH_API_KEY=${DEVSMITH_API_KEY}
      - DEVSMITH_PROJECT=my-microservices
      - DEVSMITH_SERVICE=user-service
  
  order-service:
    environment:
      - DEVSMITH_API_KEY=${DEVSMITH_API_KEY}
      - DEVSMITH_PROJECT=my-microservices
      - DEVSMITH_SERVICE=order-service
```

**All microservices copy the same logger.go file, customize service names, log to same project. Dashboard filters by `service_name`.**

---

## üìã Checklist for Implementation

### Database (Week 1) ‚úÖ 75% Complete
- [x] Create `logs.projects` table - ‚úÖ Migration file ready
- [x] Add `project_id` and `service_name` columns to `logs.entries` - ‚úÖ Migration file ready
- [x] Create indexes for fast lookups - ‚úÖ Migration file ready
- [x] Write migration script - ‚úÖ 20251111_001_add_projects.sql
- [ ] Execute migration
- [ ] Test project creation

### Backend API (Week 1) 45% Remaining
- [x] Project service (models, business logic) - ‚úÖ Complete
- [x] API key generation/validation - ‚úÖ Complete (crypto/rand + bcrypt)
- [ ] Add CreateBatch() to log_entry_repository.go
- [ ] Create project_repository.go
- [ ] Batch log ingestion handler (POST /api/logs/batch)
- [ ] API key authentication middleware
- [ ] Rate limiting middleware
- [ ] Update log queries to filter by project
- [ ] Register routes in cmd/logs/main.go

### Sample Files (Week 2)
- [ ] JavaScript sample (docs/integrations/javascript/logger.js)
- [ ] Python sample (docs/integrations/python/logger.py)
- [ ] Go sample (docs/integrations/go/logger.go)
- [ ] Express.js framework example
- [ ] Flask framework example
- [ ] Gin framework example

### Frontend (Week 3)
- [ ] Project management page
- [ ] Create project modal
- [ ] API key display (one-time, copy-to-clipboard)
- [ ] API key regeneration with confirmation
- [ ] Project filter in Health dashboard
- [ ] Service name filter
- [ ] Update log display to show project/service

### Documentation (Week 2-4)
- [ ] Quick start guide per language
- [ ] API reference for batch endpoint
- [ ] Example integrations (Express, Flask, Gin)
- [ ] Troubleshooting guide
- [ ] Sample file customization guide

### Testing (Week 4)
- [ ] Unit tests for API key generation
- [ ] Integration tests for batch ingestion
- [ ] Performance testing (14K-33K logs/second target)
- [ ] Security testing (API key validation, bcrypt strength)

---

## üéì Key Design Decisions

### 1. Why Universal API (Not SDKs)?
**Decision:** Provide Universal REST API + Copy-Paste Sample Files, NOT maintained SDKs.

**Rationale:**
- **Zero Maintenance:** No npm/PyPI/Go module packages to maintain
- **100x Performance:** Batching eliminates SDK overhead (100 logs in 10-50ms vs 1-5 seconds)
- **Universal Support:** Works with ANY language (even shell scripts: `curl -X POST ...`)
- **User Customization:** Users modify sample files for their needs
- **Community Scalable:** Users can contribute samples for Ruby, PHP, Rust, etc.

**Trade-off:** Users must copy-paste file (not `npm install`), but gain full control.

---

### 2. Why API Keys (Not OAuth)?
**Decision:** Use API keys for authentication, not OAuth tokens.

**Rationale:**
- API keys are long-lived (suitable for production apps)
- OAuth tokens expire (require refresh logic)
- API keys simpler for programmatic access
- Industry standard (Datadog, Sentry, Loggly all use API keys)

**Security:** Hashed storage (bcrypt) + HTTPS + rate limiting = secure.

---

### 3. Why Batch Ingestion (Not Individual)?
**Decision:** Client buffers logs and sends in batches of 100 or every 5 seconds.

**Rationale:**
- **Performance:** 100x faster (100 logs in 10-50ms vs 1-5 seconds)
- **Reduced Network Overhead:** 1 HTTP request vs 100 requests
- **Scalability:** Backend handles fewer connections
- **Reliability:** Retry batch on failure, not individual logs

**Implementation:**
- Client-side buffering in sample files
- Backend batch INSERT (single query for 100 rows)
- Connection pool optimization (10 max, 5 idle)

**Trade-off:** Slight delay (up to 5 seconds), but acceptable for most use cases.

---

## üîç Next Steps

1. **Complete document update** - ‚úÖ Done (this file)
2. **Implement Week 1 remaining tasks** (45%):
   - Add CreateBatch() to log_entry_repository.go (30 minutes)
   - Create project_repository.go (30 minutes)
   - Create batch ingestion handler (45 minutes)
   - Register routes (15 minutes)
   - Execute migration (5 minutes)
   - Test end-to-end (20 minutes)
3. **Week 2: Create sample files** - JavaScript, Python, Go samples
4. **Week 3: Dashboard enhancements** - Project/service filtering
5. **Week 4: Testing & documentation** - Performance benchmarks, guides

---

**Questions Resolved:**
- ‚úÖ Deployment model: Self-hosted (with optional SaaS later)
- ‚úÖ SDK vs API: Universal API + Sample Files (not SDKs)
- ‚úÖ Language priority: JavaScript first, then Python, then Go
- ‚úÖ MVP features: API keys, batch ingestion, dashboard filtering

---

**Status**: Architecture Document 100% Complete ‚úÖ | Implementation In Progress (Week 1 - 75% Complete) ‚úÖ
